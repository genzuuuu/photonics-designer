{"cells":[{"cell_type":"code","execution_count":null,"id":"initial_id","metadata":{"collapsed":true,"id":"initial_id"},"outputs":[],"source":["# first download Neo4j desktop and create a database of version 5.11 and install the plugins: Neosemantics, APOC"]},{"cell_type":"code","outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: sentence-transformers in ./.venv/lib/python3.11/site-packages (2.6.1)\r\n","Requirement already satisfied: rank_bm25 in ./.venv/lib/python3.11/site-packages (0.2.2)\r\n","Requirement already satisfied: transformers<5.0.0,>=4.32.0 in ./.venv/lib/python3.11/site-packages (from sentence-transformers) (4.39.3)\r\n","Requirement already satisfied: tqdm in ./.venv/lib/python3.11/site-packages (from sentence-transformers) (4.66.2)\r\n","Collecting torch>=1.11.0 (from sentence-transformers)\r\n","  Obtaining dependency information for torch>=1.11.0 from https://files.pythonhosted.org/packages/96/23/18b9c16c18a77755e7f15173821c7100f11e6b3b7717bea8d729bdeb92c0/torch-2.2.2-cp311-none-macosx_11_0_arm64.whl.metadata\r\n","  Using cached torch-2.2.2-cp311-none-macosx_11_0_arm64.whl.metadata (25 kB)\r\n","Requirement already satisfied: numpy in ./.venv/lib/python3.11/site-packages (from sentence-transformers) (1.26.4)\r\n","Requirement already satisfied: scikit-learn in ./.venv/lib/python3.11/site-packages (from sentence-transformers) (1.4.1.post1)\r\n","Requirement already satisfied: scipy in ./.venv/lib/python3.11/site-packages (from sentence-transformers) (1.13.0)\r\n","Requirement already satisfied: huggingface-hub>=0.15.1 in ./.venv/lib/python3.11/site-packages (from sentence-transformers) (0.22.2)\r\n","Requirement already satisfied: Pillow in ./.venv/lib/python3.11/site-packages (from sentence-transformers) (10.3.0)\r\n","Requirement already satisfied: filelock in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.3)\r\n","Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.3.1)\r\n","Requirement already satisfied: packaging>=20.9 in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (23.2)\r\n","Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\r\n","Requirement already satisfied: requests in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\r\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.10.0)\r\n","Requirement already satisfied: sympy in ./.venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\r\n","Requirement already satisfied: networkx in ./.venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\r\n","Requirement already satisfied: jinja2 in ./.venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\r\n","Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (2023.12.25)\r\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in ./.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.15.2)\r\n","Requirement already satisfied: safetensors>=0.4.1 in ./.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.4.2)\r\n","Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (1.3.2)\r\n","Requirement already satisfied: threadpoolctl>=2.0.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (3.4.0)\r\n","Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\r\n","Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\r\n","Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.6)\r\n","Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.2.1)\r\n","Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\r\n","Requirement already satisfied: mpmath>=0.19 in ./.venv/lib/python3.11/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\r\n","Using cached torch-2.2.2-cp311-none-macosx_11_0_arm64.whl (59.7 MB)\r\n","Installing collected packages: torch\r\n","Successfully installed torch-2.2.2\r\n","\r\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\r\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n","Requirement already satisfied: stop_words in ./.venv/lib/python3.11/site-packages (2018.7.23)\r\n","\r\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\r\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n","zsh:1: command not found: nvidia-smi\r\n"]}],"source":["!pip install -U sentence-transformers rank_bm25\n","!pip install stop_words\n","!nvidia-smi"],"metadata":{"ExecuteTime":{"end_time":"2024-04-09T14:48:46.082895Z","start_time":"2024-04-09T14:48:37.581369Z"},"id":"802a47d0bc4daad7","outputId":"b11e968e-6f6e-48b2-a9c2-2a1feb7f2d51"},"id":"802a47d0bc4daad7","execution_count":null},{"cell_type":"code","outputs":[],"source":["# Importing required libraries\n","import json\n","from sentence_transformers import SentenceTransformer, CrossEncoder, util\n","import time\n","import gzip\n","import os\n","import torch"],"metadata":{"ExecuteTime":{"end_time":"2024-04-09T14:49:16.894562Z","start_time":"2024-04-09T14:49:11.871195Z"},"id":"35370381b3e7e062"},"id":"35370381b3e7e062","execution_count":null},{"cell_type":"code","outputs":[],"source":["# For semantic search, we use SentenceTransformer('multi-qa-MiniLM-L6-cos-v1') to encode all passages.\n","\n","bi_encoder = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1')\n","bi_encoder.max_seq_length = 256\n","top_k = 100"],"metadata":{"ExecuteTime":{"end_time":"2024-04-09T14:49:18.108188Z","start_time":"2024-04-09T14:49:16.895881Z"},"id":"23e76f4d51464948"},"id":"23e76f4d51464948","execution_count":null},{"cell_type":"code","outputs":[],"source":["cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n"],"metadata":{"ExecuteTime":{"end_time":"2024-04-09T14:49:20.267055Z","start_time":"2024-04-09T14:49:20.000506Z"},"id":"6f36ade1e64de4f4"},"id":"6f36ade1e64de4f4","execution_count":null},{"cell_type":"code","outputs":[{"name":"stdout","output_type":"stream","text":["Passages: 6\n"]}],"source":["# this is the context information for using semantic search\n","passages = [\"Environmental sustainability is the ability to maintain an ecological balance in our planet's natural environment and conserve natural resources to support the wellbeing of current and future generations.\",\n","            \"Climate action: Acting now to stop global warming. Life below water: Avoiding the use of plastic bags to keep the oceans clean. Life on land: Planting trees to help protect the environment. Responsible consumption and production: Recycling items such as paper, plastic, glass and aluminum.\",\n","            \"Characteristics of sustainability or sustainable development are: Reduce emission of greenhouse gases, which will reduce global warming and help in preserving the environment. Use of natural and biodegradable materials for reducing the impact on the environment.\",\n","            \"However, it refers to four distinct areas: environmental, social, economic, and human   â€“ known as the four pillars of sustainability.\",\n","            \"Environmental sustainability is important because of how much energy, food, and human-made resources we use every day. Rapid population growth has resulted in increased farming and manufacturing, leading to more greenhouse gas emissions, unsustainable energy use, and deforestation.\",\n","            \"Sustainability maintains the health and biocapacity of the environment. Sustainability supports the well-being of individuals and communities. Sustainability promotes a better economy where there is little waste and pollution, fewer emissions, more jobs, and a better distribution of wealth.\"]\n","\n","print(\"Number of Passages:\", len(passages))"],"metadata":{"ExecuteTime":{"end_time":"2024-04-09T14:49:51.858428Z","start_time":"2024-04-09T14:49:51.853379Z"},"id":"78a57b0ec90ea8d","outputId":"8e4f75ee-19b1-4f74-cf11-3d71e91de927"},"id":"78a57b0ec90ea8d","execution_count":null},{"cell_type":"code","outputs":[{"data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c9e6de83f234897bc95643af579eca9"}},"metadata":{},"output_type":"display_data"}],"source":["corpus_embeddings = bi_encoder.encode(passages, convert_to_tensor=True, show_progress_bar=True)\n"],"metadata":{"ExecuteTime":{"end_time":"2024-04-09T14:49:59.178068Z","start_time":"2024-04-09T14:49:56.990763Z"},"id":"835015f7978d5b88","outputId":"01353b8d-9e71-4679-8fe1-bdea52c76d3d","colab":{"referenced_widgets":["7c9e6de83f234897bc95643af579eca9"]}},"id":"835015f7978d5b88","execution_count":null},{"cell_type":"code","outputs":[{"data":{"text/plain":"  0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0f5c917afa14c7791b3ba88514d38d5"}},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["tokenized_corpus... [['environmental', 'sustainability', 'ability', 'maintain', 'ecological', 'balance', \"planet's\", 'natural', 'environment', 'conserve', 'natural', 'resources', 'support', 'wellbeing', 'current', 'future', 'generations'], ['climate', 'action', 'acting', 'stop', 'global', 'warming', 'life', 'water', 'avoiding', 'use', 'plastic', 'bags', 'oceans', 'clean', 'life', 'land', 'planting', 'trees', 'help', 'protect', 'environment', 'responsible', 'consumption', 'production', 'recycling', 'items', 'paper', 'plastic', 'glass', 'aluminum'], ['characteristics', 'sustainability', 'sustainable', 'development', 'reduce', 'emission', 'greenhouse', 'gases', 'reduce', 'global', 'warming', 'help', 'preserving', 'environment', 'use', 'natural', 'biodegradable', 'materials', 'reducing', 'impact', 'environment'], ['refers', 'distinct', 'areas', 'environmental', 'social', 'economic', 'human', 'â€“', 'known', 'pillars', 'sustainability'], ['environmental', 'sustainability', 'important', 'energy', 'food', 'human-made', 'resources', 'use', 'day', 'rapid', 'population', 'growth', 'resulted', 'increased', 'farming', 'manufacturing', 'leading', 'greenhouse', 'gas', 'emissions', 'unsustainable', 'energy', 'use', 'deforestation'], ['sustainability', 'maintains', 'health', 'biocapacity', 'environment', 'sustainability', 'supports', 'well-being', 'individuals', 'communities', 'sustainability', 'promotes', 'better', 'economy', 'little', 'waste', 'pollution', 'fewer', 'emissions', 'jobs', 'better', 'distribution', 'wealth']]\n"]}],"source":["from rank_bm25 import BM25Okapi\n","#from sklearn.feature_extraction import stop_words\n","from sklearn.feature_extraction import _stop_words\n","# from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS as sklearn_stop_words\n","import string\n","from tqdm.autonotebook import tqdm\n","import numpy as np\n","\n","# We lower case our text and remove stop-words from indexing\n","def bm25_tokenizer(text):\n","  tokenized_doc = []\n","  for token in text.lower().split():\n","    token = token.strip(string.punctuation)\n","\n","    if len(token) > 0 and token not in _stop_words.ENGLISH_STOP_WORDS:\n","      tokenized_doc.append(token)\n","  return tokenized_doc\n","\n","tokenized_corpus = []\n","for passage in tqdm(passages):\n","  tokenized_corpus.append(bm25_tokenizer(passage))\n","\n","print(\"tokenized_corpus...\", tokenized_corpus)\n","# First thing to do is create an instance of the BM25 class, which reads in a corpus of text and does some indexing on it.\n","bm25 = BM25Okapi(tokenized_corpus)"],"metadata":{"ExecuteTime":{"end_time":"2024-04-09T14:50:05.104045Z","start_time":"2024-04-09T14:50:05.077273Z"},"id":"d5afe0b65bad8edf","outputId":"62484799-53b9-4a9a-85ea-1973ce626c96","colab":{"referenced_widgets":["e0f5c917afa14c7791b3ba88514d38d5"]}},"id":"d5afe0b65bad8edf","execution_count":null},{"cell_type":"code","outputs":[{"name":"stdout","output_type":"stream","text":["Input question: What is the second domain of sustainability?\n","Top-5 Cross-Encoder Re-ranker hits\n","However, it refers to four distinct areas: environmental, social, economic, and human   â€“ known as the four pillars of sustainability.\n"]},{"data":{"text/plain":"'However, it refers to four distinct areas: environmental, social, economic, and human   â€“ known as the four pillars of sustainability.'"},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["\n","# query is the input given by the user which need to be searched in the above 6 passages through keyword and semantic search.\n","\n","\n","\n","def search(query):\n","  print(\"Input question:\", query)\n","\n","  ####### Keyword Search through BM25 algorithm ########\n","  bm25_scores = bm25.get_scores(bm25_tokenizer(query))\n","  top_n = np.argpartition(bm25_scores, -5)[-5:]\n","  bm25_hits = [{'corpus_id': idx, 'score': bm25_scores[idx]} for idx in top_n]\n","  bm25_hits = sorted(bm25_hits, key=lambda x: x['score'], reverse=True)\n","  #print(\"Top-5 lexical search (BM25) hits\")\n","  #for hit in bm25_hits[0:5]:\n","      #print(\"\\t{:.3f}\\t{}\".format(hit['score'], passages[hit['corpus_id']].replace(\"\\n\", \" \")))\n","\n","  ##### Sematic Search #####\n","  torch.set_default_device(\"mps\")\n","  question_embedding = bi_encoder.encode(query, convert_to_tensor=True)\n","  question_embedding = question_embedding.to(\"mps\")\n","  # Both question and corpus are encoded\n","  hits = util.semantic_search(question_embedding, corpus_embeddings, top_k=top_k)\n","  hits = hits[0]\n","\n","  # First, we use a Bi-Encoder to retrieve a list of result candidates,\n","  # then you use a Cross-Encoder on this list of candidates to pick out (or rerank) the most relevant results.\n","  # This way, we benefit from the efficient retrieval method using Bi-Encoders\n","  # and the high accuracy of the Cross-Encoder, so we can use this on large scale datasets!\n","\n","  ##### Re-Ranking #####\n","  # Now, score all retrieved passages with the cross_encoder\n","  cross_inp = [[query, passages[hit['corpus_id']]] for hit in hits]\n","  cross_scores = cross_encoder.predict(cross_inp)\n","\n","  # Sort results by the cross-encoder scores\n","  for idx in range(len(cross_scores)):\n","      hits[idx]['cross-score'] = cross_scores[idx]\n","\n","\n","  #### Output of top-5 cases ######\n","  #print(\"Top-5 Bi-Encoder Retrieval hits\")\n","  hits = sorted(hits, key=lambda x: x['score'], reverse=True)\n","  #for hit in hits[0:5]:\n","      #print(\"\\t{:.3f}\\t{}\".format(hit['score'], passages[hit['corpus_id']].replace(\"\\n\", \" \")))\n","\n","  print(\"Top-5 Cross-Encoder Re-ranker hits\")\n","  hits = sorted(hits, key=lambda x: x['cross-score'], reverse=True)\n","  hit = hits[0]\n","  #for hit in hits[0:5]:\n","  #print(\"\\t{:.3f}\\t{}\".format(hit['cross-score'], passages[hit['corpus_id']].replace(\"\\n\", \" \")))\n","  print(passages[hit['corpus_id']])\n","  return passages[hit['corpus_id']]\n","\n","fetched = search(query = \"What is the second domain of sustainability?\")\n","fetched"],"metadata":{"ExecuteTime":{"end_time":"2024-04-09T14:50:27.806421Z","start_time":"2024-04-09T14:50:23.644524Z"},"id":"eaf38e9bb7c1c3de","outputId":"8c2976c9-a003-488d-c791-620d7a1e3d24"},"id":"eaf38e9bb7c1c3de","execution_count":null},{"cell_type":"code","outputs":[],"source":["\n","# if the context information are only strings\n","from langchain_community.llms import Replicate\n","\n","os.environ[\"REPLICATE_API_TOKEN\"] = \"ENTER REPLICATE API KEY HERE\"\n","\n","llm = Replicate(model=\"mistralai/mixtral-8x7b-instruct-v0.1:cf18decbf51c27fed6bbdc3492312c1c903222a56e3fe9ca02d6cbe5198afc10\", model_kwargs={\"temperature\": 0.75, \"max_length\": 500, \"top_p\": 1},)\n","prompt = \"\"\"\n","given the context here: {}, answer the question:\n","What is the second domain of sustainability?\n","\"\"\".format(fetched)\n","\n","# it might take a while for replicate to boot the model in their hardware\n","llm(prompt)"],"metadata":{"id":"45d829116dba6ec3"},"id":"45d829116dba6ec3","execution_count":null},{"cell_type":"code","outputs":[],"source":["# if we want to store the context information into a vector database\n","\n","from reportlab.pdfgen.canvas import Canvas\n","canvas = Canvas(\"GFG.pdf\")\n","canvas.drawString(100, 100, fetched)\n","canvas.showPage()\n","canvas.save()\n"],"metadata":{"ExecuteTime":{"end_time":"2024-04-09T15:03:00.849512Z","start_time":"2024-04-09T15:03:00.839636Z"},"id":"d108df3ca9b8d0a0"},"id":"d108df3ca9b8d0a0","execution_count":null},{"cell_type":"code","outputs":[{"data":{"text/plain":"'However, it refers to four distinct areas: environmental, social, economic, and human   â€“ known as the four pillars of sustainability.\\n'"},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["import os\n","from langchain.document_loaders import PyPDFLoader\n","from langchain.text_splitter import CharacterTextSplitter\n","from langchain.vectorstores import Chroma\n","from langchain.embeddings import OpenAIEmbeddings\n","\n","### Putting the result of semantic search in the below pdf\n","pdf_loader = PyPDFLoader('GFG.pdf'  )\n","documents = pdf_loader.load()\n","document = list(documents[0])[0][1]\n","document"],"metadata":{"ExecuteTime":{"end_time":"2024-04-09T15:03:01.191253Z","start_time":"2024-04-09T15:03:01.176666Z"},"id":"da6323b464681794","outputId":"7c845de5-023e-4a52-82a0-1a6d5b9a205b"},"id":"da6323b464681794","execution_count":null},{"cell_type":"code","outputs":[{"name":"stderr","output_type":"stream","text":["/Users/jasonliu/PycharmProjects/pythonProject/.venv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.0.9 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n","  warn_deprecated(\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"data":{"text/plain":"<langchain_community.vectorstores.chroma.Chroma at 0x16364fc10>"},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["# we split the data into chunks of 1,000 characters, with an overlap\n","# of 200 characters between the chunks, which helps to give better results\n","# and contain the context of the information between chunks\n","\n","text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n","documents = text_splitter.split_documents(documents)\n","\n","\n","# we create our vectorDB, using the OpenAIEmbeddings transformer to create\n","# embeddings from our text chunks. We set all the db information to be stored\n","# inside the ./data directory, so it doesn't clutter up our source files\n","\n","vectordb = Chroma.from_documents(\n","  documents,\n","  embedding=OpenAIEmbeddings(),\n","  persist_directory='./data2'\n",")\n","# vectordb.persist()\n","vectordb\n"],"metadata":{"ExecuteTime":{"end_time":"2024-04-09T15:03:03.539193Z","start_time":"2024-04-09T15:03:01.382747Z"},"id":"1fea54ac6daf5995","outputId":"2f53abeb-0e85-4188-b855-3f36ce2b2b4d"},"id":"1fea54ac6daf5995","execution_count":null},{"cell_type":"code","outputs":[],"source":["from langchain.chains import RetrievalQA\n","from langchain.llms import OpenAI\n","from langchain_community.llms import Replicate\n","\n","os.environ[\"REPLICATE_API_TOKEN\"] = \"ENTER REPLICATE API KEY HERE\"\n","\n","qa_chain1 = RetrievalQA.from_chain_type(\n","    llm = Replicate(model=\"mistralai/mixtral-8x7b-instruct-v0.1:cf18decbf51c27fed6bbdc3492312c1c903222a56e3fe9ca02d6cbe5198afc10\", model_kwargs={\"temperature\": 0.75, \"max_length\": 500, \"top_p\": 1},),\n","    retriever=vectordb.as_retriever(search_kwargs={'k': 7}),\n","    return_source_documents=True\n",")"],"metadata":{"ExecuteTime":{"end_time":"2024-04-09T15:03:07.181177Z","start_time":"2024-04-09T15:03:07.175680Z"},"id":"6b168d4759de365c"},"id":"6b168d4759de365c","execution_count":null},{"cell_type":"code","outputs":[{"name":"stderr","output_type":"stream","text":["/Users/jasonliu/PycharmProjects/pythonProject/.venv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n","  warn_deprecated(\n","Number of requested results 7 is greater than number of elements in index 2, updating n_results = 2\n"]},{"name":"stdout","output_type":"stream","text":["The second domain of sustainability, based on the \"four pillars of sustainability\" you mentioned, is social sustainability. This domain focuses on issues such as social equity, human well-being, and relationships between communities. It's about creating a society that is fair, inclusive, and provides opportunities for all its members to thrive.\n"]}],"source":["# we can now execute queries against our Q&A chain\n","result = qa_chain1({'query': 'What is the second domain of sustainability?'})\n","print(result['result'])"],"metadata":{"ExecuteTime":{"end_time":"2024-04-09T15:03:36.829129Z","start_time":"2024-04-09T15:03:30.104177Z"},"id":"7f7d0fe82a86752a","outputId":"751804d7-b356-4f08-9229-7b98f41e0b1b"},"id":"7f7d0fe82a86752a","execution_count":null},{"cell_type":"code","outputs":[],"source":[],"metadata":{"id":"5c10e7408a2b3667"},"id":"5c10e7408a2b3667","execution_count":null}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.6"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}